{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f71ff94",
   "metadata": {},
   "source": [
    "### **Scraping a book website**\n",
    "\n",
    "First, go to this link:\n",
    "\n",
    "https://books.toscrape.com/\n",
    "\n",
    "\n",
    "\n",
    "For today, let's just focus on the music section:\n",
    "\n",
    "https://books.toscrape.com/catalogue/category/books/music_14/index.html\n",
    "\n",
    "Our goal will be to save the following information to a csv file for every book in the music section:\n",
    "- Title\n",
    "- Rating\n",
    "- UPC\n",
    "- Product Type\n",
    "- Price (excl. tax)\n",
    "- Price (incl. tax)\n",
    "- Tax\n",
    "- Availability\n",
    "- Number of reviews\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0369ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing libaries: you will only need to run this once\n",
    "# can also be ran in your terminal with: pip install requests beautifulsoup4 pandas\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install --user requests beautifulsoup4 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ef28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: make a request to the website and get the HTML content\n",
    "url = \"https://books.toscrape.com/catalogue/category/books/music_14/index.html\" # this is the url to the website we want to scrape\n",
    "\n",
    "response = requests.get(url) # this sends a GET request to the website and stores the response in the variable \"response\"\n",
    "\n",
    "print(\"status code:\", response.status_code) # this prints the status code of the response. A status code of 200 means the request was successful, while a status code of 404 means the page was not found.\n",
    "\n",
    "html = response.text # this gets the HTML content of the page as a string and stores it in the variable \"html\"\n",
    "\n",
    "print(html[:1000]) # this prints the first 1000 characters of the HTML content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9bf31",
   "metadata": {},
   "source": [
    "Now go back to this link: https://books.toscrape.com/catalogue/category/books/music_14/index.html\n",
    "\n",
    "1. Right click\n",
    "2. Inspect\n",
    "3. Click the top left icon that looks like a square with an arrow in the bottom right corner\n",
    "4. Hover over the area for the first book\n",
    "5. Click the corresponding html element that is highlighted\n",
    "6. Copy it\n",
    "7. Paste it below\n",
    "8. Go back and hover over the lists of similar elements-- notice how each \"product pod\" is getting highlighted as you do\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b2b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should look like this:\n",
    "<li class=\"col-xs-6 col-sm-4 col-md-3 col-lg-3\">\n",
    "    <article class=\"product_pod\">\n",
    "            <div class=\"image_container\">\n",
    "                    <a href=\"../../../rip-it-up-and-start-again_986/index.html\"><img src=\"../../../../media/cache/81/c4/81c4a973364e17d01f217e1188253d5e.jpg\" alt=\"Rip it Up and Start Again\" class=\"thumbnail\"></a>\n",
    "            </div>\n",
    "                <p class=\"star-rating Five\">\n",
    "                    <i class=\"icon-star\"></i>\n",
    "                    <i class=\"icon-star\"></i>\n",
    "                    <i class=\"icon-star\"></i>\n",
    "                    <i class=\"icon-star\"></i>\n",
    "                    <i class=\"icon-star\"></i>\n",
    "                </p>\n",
    "            <h3><a href=\"../../../rip-it-up-and-start-again_986/index.html\" title=\"Rip it Up and Start Again\">Rip it Up and ...</a></h3> # this is an important line-- it gives us the hyperlink to the page\n",
    "            <div class=\"product_price\">\n",
    "        <p class=\"price_color\">Â£35.02</p>\n",
    "<p class=\"instock availability\">\n",
    "    <i class=\"icon-ok\"></i>\n",
    "        In stock\n",
    "</p>\n",
    "    <form>\n",
    "        <button type=\"submit\" class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\">Add to basket</button>\n",
    "    </form>            \n",
    "            </div>\n",
    "    </article>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67568dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pull each hyperlink from each product pod so that we can access the individual pages for each book\n",
    "soup = BeautifulSoup(html, \"html.parser\") # creates a beautifulsoup object from the HTML content, which allows us to easily navigate and search the HTML structure\n",
    "product_pods = soup.find_all(\"article\", class_=\"product_pod\") # this finds all the \"article\" tags with the class \"product_pod\" and stores them in a list called \"product_pods\". Each \"article\" tag represents a product on the page.\n",
    "links = [] \n",
    "\n",
    "for pod in product_pods: # this loops through each product pod in the list of product pods\n",
    "    link = pod.h3.a[\"href\"] # this gets the hyperlink from the \"a\" tag inside the \"h3\" tag of the product pod. The \"href\" attribute contains the URL of the individual book page.\n",
    "    links.append(link) # this adds the hyperlink to the list of existing hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e637ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fdc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721395b",
   "metadata": {},
   "source": [
    "Notice that these are relative hyperlinks. if we tried to copy and paste these into a browser, they would not return a valid page\n",
    "\n",
    "But let's try clicking on the first book on the page and looking at the hyperlink structure: https://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\n",
    "\n",
    "So if we append \"https://books.toscrape.com/catalogue\" to the beginning of our hyperlinks, this will return valid pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6443d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "page_url = \"https://books.toscrape.com/catalogue/category/books/music_14/index.html\" # this is the url of the page we are scraping, which we will use as the base url to create the full urls for each book page\n",
    "\n",
    "clean_links = [urljoin(page_url, link) for link in links] # this creates a new list called \"clean_links\" that contains the full urls for each book page by joining the base url with each hyperlink in the \"links\" list using the urljoin function from the urllib.parse library\n",
    "\n",
    "for link in clean_links: \n",
    "    print(link)\n",
    "\n",
    " # now we can loop through each of the clean links and make a request to each book page to get more information about each book, such as the title, price, stock availability, and star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f76d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's make a request to the first link in our list and examine its html structure\n",
    "first_book_url = clean_links[0]\n",
    "\n",
    "response = requests.get(first_book_url)\n",
    "print(\"status code:\", response.status_code)\n",
    "\n",
    "book_html = response.text\n",
    "\n",
    "book_soup = BeautifulSoup(book_html, \"html.parser\")\n",
    "\n",
    "print(book_soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97961c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title\n",
    "title = book_soup.find(\"div\", class_=\"product_main\").find(\"h1\").get_text(strip=True)\n",
    "\n",
    "# rating (stored as a class, e.g. \"star-rating Five\")\n",
    "rating = book_soup.find(\"p\", class_=\"star-rating\")[\"class\"][1]\n",
    "\n",
    "print(\"title:\", title)\n",
    "print(\"rating:\", rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf83c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product information table\n",
    "table_rows = book_soup.find(\"table\", class_=\"table table-striped\").find_all(\"tr\")\n",
    "\n",
    "product_info = {}\n",
    "for row in table_rows:\n",
    "    key = row.find(\"th\").get_text(strip=True)\n",
    "    value = row.find(\"td\").get_text(strip=True)\n",
    "    product_info[key] = value\n",
    "\n",
    "print(table_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"upc:\", product_info.get(\"UPC\"))\n",
    "print(\"product type:\", product_info.get(\"Product Type\"))\n",
    "print(\"price (excl. tax):\", product_info.get(\"Price (excl. tax)\"))\n",
    "print(\"price (incl. tax):\", product_info.get(\"Price (incl. tax)\"))\n",
    "print(\"tax:\", product_info.get(\"Tax\"))\n",
    "print(\"availability:\", product_info.get(\"Availability\"))\n",
    "print(\"number of reviews:\", product_info.get(\"Number of reviews\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24127dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning output a bit further\n",
    "\n",
    "# --- clean price fields: extract numeric values ---\n",
    "price_excl_tax = float(\n",
    "    re.search(r\"[\\d.]+\", product_info[\"Price (excl. tax)\"]).group()\n",
    ")\n",
    "\n",
    "price_incl_tax = float(\n",
    "    re.search(r\"[\\d.]+\", product_info[\"Price (incl. tax)\"]).group()\n",
    ")\n",
    "\n",
    "tax = float(\n",
    "    re.search(r\"[\\d.]+\", product_info[\"Tax\"]).group()\n",
    ")\n",
    "\n",
    "# --- clean availability ---\n",
    "availability_text = product_info[\"Availability\"]\n",
    "\n",
    "# availability flag\n",
    "available_flag = \"y\" if \"In stock\" in availability_text else \"n\"\n",
    "\n",
    "# number available (extract integer)\n",
    "match = re.search(r\"\\((\\d+) available\\)\", availability_text)\n",
    "number_available = int(match.group(1)) if match else None\n",
    "\n",
    "# print cleaned results\n",
    "print(\"price_excl_tax:\", price_excl_tax)\n",
    "print(\"price_incl_tax:\", price_incl_tax)\n",
    "print(\"tax:\", tax)\n",
    "print(\"available_flag:\", available_flag)\n",
    "print(\"number_available:\", number_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "total = len(clean_links)\n",
    "\n",
    "for i, url in enumerate(clean_links, start=1): # loops through each clean link in our list\n",
    "    print(f\"scraping {i}/{total}: {url}\")\n",
    "\n",
    "    response = requests.get(url) # grabs the html for the url\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") \n",
    "\n",
    "    title = soup.find(\"div\", class_=\"product_main\").find(\"h1\").get_text(strip=True) # title\n",
    "    rating = soup.find(\"p\", class_=\"star-rating\")[\"class\"][1] # rating\n",
    "\n",
    "    table_rows = soup.find(\"table\", class_=\"table table-striped\").find_all(\"tr\") # product information table\n",
    "    product_info = {}\n",
    "    for row in table_rows:\n",
    "        key = row.find(\"th\").get_text(strip=True)\n",
    "        value = row.find(\"td\").get_text(strip=True)\n",
    "        product_info[key] = value\n",
    "\n",
    "    price_excl_tax = float(re.search(r\"[\\d.]+\", product_info[\"Price (excl. tax)\"]).group()) # cleans prices\n",
    "    price_incl_tax = float(re.search(r\"[\\d.]+\", product_info[\"Price (incl. tax)\"]).group()) # cleans prices\n",
    "    tax = float(re.search(r\"[\\d.]+\", product_info[\"Tax\"]).group()) # cleans taxes\n",
    "\n",
    "    availability_text = product_info[\"Availability\"] \n",
    "    available_flag = \"y\" if \"In stock\" in availability_text else \"n\" # cleans availability\n",
    "    match = re.search(r\"\\((\\d+)\\s+available\\)\", availability_text)\n",
    "    number_available = int(match.group(1)) if match else None\n",
    " \n",
    "    rows.append({ # saves the final dataframe \n",
    "        \"book_url\": url, \n",
    "        \"title\": title,\n",
    "        \"rating\": rating,\n",
    "        \"upc\": product_info.get(\"UPC\"),\n",
    "        \"product_type\": product_info.get(\"Product Type\"),\n",
    "        \"price_excl_tax\": price_excl_tax,\n",
    "        \"price_incl_tax\": price_incl_tax,\n",
    "        \"tax\": tax,\n",
    "        \"available_flag\": available_flag,\n",
    "        \"number_available\": number_available,\n",
    "        \"number_of_reviews\": product_info.get(\"Number of reviews\"),\n",
    "    })\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "df_books = pd.DataFrame(rows)\n",
    "df_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7614ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books.to_csv(\"books.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
